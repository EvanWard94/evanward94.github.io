<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Milestone 2</title>
    <link rel="stylesheet" href = "Styling.css">
</head>
<body>


<div id = "top">
    <h1>Milestone 2</h1>
    <nav class = "navbar">
        <ul>
            <li>
                <a href = "https://evanward94.github.io">Home</a>
            </li>
            <li>
                <a href = "Milestone2.html">Milestone 2</a>
            </li>
        </ul>
    </nav>

    <h2>A. Task/Problem Definition</h2>

    <h3>1. Introduce your problem. </h3>

    <p>The use of videos in higher education is a common multimedia teaching tool that is known to enhance students’ understanding and learning of class materials (Berk, 2009; Mayor, 2001). Closed-caption videos were developed to help hearing impaired individuals, and are also widely used to benefit English as second language learners (Zamoon, 1996). Further, studies have shown that closed-captioned videos also benefit literate capable students with no hearing impairment (Gernsbarcher, 2015). Closed-captions can be defined as the synchronized text transcription of audio and video content, which is displayed on the screen as the content is viewed. ‘Closed’ indicates that a viewer has the option to enable or disable this function. Various platforms, such as Zoom, YouTube, and TikTok, offer the option to creators to automatically generate captions on audio and video content produced. While many of these platforms have been integrated in the classroom, both online and face to face, ELC, the primary online learning management system for the University of Georgia, lacks an adequate, automatic closed-captioning function. Looking at Criterion 1.2.5, Audio Description (Pre-recorded) (Level AA) from the Web Content Accessibility Guidelines, the software behind ELC, Desire2Learn (D2L), has a conformance level of ‘Not Supported’. Although the Web Content Accessibility Guidelines state that ‘users control the content that they produce’, the responsibility is left to the instructor to outsource the creation of closed-captions and transcripts for their audio and video content, or create the closed-captions and transcripts themselves. While uploading video and audio content through ELC itself offers no automatic captioning tool, Kaltura, the media storage and streaming solution, which is integrated with ELC, offers the option to do so. Yet, another problem lies in the accuracy provided by the closed-caption function of Kaltura. Kaltura boasts an accuracy of 70-80% for the closed-captions their software produces (Disability Resource Center, University of Georgia), yet the industry standard for closed-captioning is 99% (fcc.gov). ELC, then, lacks an integrated function to provide instructors with a means to produce closed-captions and transcripts which are adequate, and accurately reflect the content being relayed in audio and video content. Inadequate closed-captions and transcripts prove to be useless to a viewer, and can be placed in the same category as content that has no closed-captioning or transcripts whatsoever (National Association of the Deaf). Closed-captions and transcripts are meant to portray the content a user is viewing, which is important in the classroom as well. If a student cannot understand to the same extent as students who have no hearing impairment, this could be the cause for lack of success in the classroom due to the information being inaccessible. Thus, ELC, as the learning management system for the University of Georgia, should provide a means for instructors to create automatic closed-captions and transcripts with at least 99% accuracy, so that audio and video content can be made accessible predominantly to students with hearing impairments and language barriers, but to all students as well. </p>

    <b>Seven Stages of Action From the Perspective of a Student User</b>

    <div class = "number">
        <ol type = "1">
            <li>Goal: View video/audio content uploaded by an instructor  with the option to turn closed-captioning on/off, or obtain a transcript </li>
            <li>Plan: Determine if I, as a user, want closed-captioning or transcripts to be turned on/off, and see if the option to obtain transcripts is available </li>
            <li>Specify: If available, closed-captioning should be turned on and a transcript should be accessible. </li>
            <li>Perform: Click on the ‘CC’ button to turn closed-captioning on, and select the ‘Transcript’ option to obtain a transcript</li>
            <li>Perceive: Closed-captioning appears at the bottom of the video/audio content screen or the transcript appears below the content</li>
            <li>Interpret: I evaluate if the words are coherent to determine the accuracy of the transcription of the content. </li>
            <li>Compare: If the transcriptions and closed-captioning is easily understood, I am able to discern the content relayed by the instructor. </li>
    </ol>
</div>

    <b>Seven Stages of Action From the Perspective of an Instructor User</b>

<div class = "number2">
    <ol type = "1">
        <li>Goal: Provide the option of closed-captioning and transcripts to all content-viewers (students). </li>
        <li>Plan: Determine how to create the closed-captions/transcripts, either through a manual process or through outsourcing. </li>
        <li>Specify: I want to include closed-captions and transcripts myself, without outsourcing. </li>
        <li>Perform: I navigate to Kaltura and upload the desired audio/video content. I will then edit the video and select ‘Captions’ in the navigation bar and add the file containing the closed-captions and time stamps. If the file does not exist, I will create it. I go to the desired course and navigate to ‘Existing Activities’. From there, I locate ‘My Media’. I embed the file and save it so that it can be viewed by desired viewers. </li>
        <li>Perceive: Viewers should have the ability to choose if they want to view closed-captions/transcripts. </li>
        <li>Interpret: It is time consuming to transcribe videos manually. The drawbacks for using humans for transcription is time and money to create an SRT, or other closed-captioning file, but viewers are able to access closed-captioning. </li>
        <li>Compare: The closed-captions are 100% accurate and match the timing of the individual speaking in the audio/video content. </li>
    </ol>
</div>


    <div class = "signifiers">
        <b>Signifiers</b>
    <ul>
        <li>‘Transcripts’ label is beneath the video/audio content</li>
        <li>Closed-captions appear at the bottom of the video/audio content screen </li>
    </ul>
        <b>Affordances</b>
        <ul>
            <li>Closed-captioning and transcripts are shown, if provided by the instructor, and the user enables this option</li>
            <li>Instructors have the option to manually transcribe their video/audio content, or outsource the creation of such prior to the content being uploaded</li>
        </ul>

        <b>Properties</b>
        <ul>
            <li>Closed-captions have a white font color with a black background </li>
            <li>Transcripts are text with timestamps</li>
        </ul>

        <h3>2. Identify Your Potential Users. </h3>

        <p>The potential users can be identified as both instructors and students, but more specifically students with hearing impairments and those whose second language is English in English-speaking classrooms, like those at the University of Georgia.</p>
        </div>

    <h2>B. Analysis of Existing Solutions</h2>

    <h3>1. Describe existing solutions. </h3>

    <p>Instructors are able to manually create closed captioning on videos posted in a course either themselves or through outsourcing. There are two ways to upload a video onto ELC. One way involves uploading directly from your computer and having the option to add closed-captions using an SRT file. However, depending on the video, ELC may not support this type of video and only the audio will be visible. Creating manual closed-captions requires manually watching the video and adding correct time-stamps for each spoken sentence in each certain segment in the uploaded content. Another way to upload a video is through Kaltura. Kaltura, which is integrated with ELC, is a media storage and streaming solution. Kaltura has more support for different video types and allows for editing to add closed-captions through an external file. Another way to add closed-captions is through the request of machine captioning, which has an “accuracy rate of 70-80%” and takes about thirty minutes depending on the size of the file (Kaltura Documentation). Such solutions require additional time on the part of the instructor to ensure that the closed-captions/transcripts are accurate and must plan ahead if they are to transcribe the video themselves. It typically takes five to ten times the duration of the video just to add closed-captions and transcribe it (Enamorado, Sofia). Instructors also have the option to upload their video to a third party platform that supplies auto-captioning and provide a link on ELC. For example, an instructor could create all video and audio content on Zoom, which has automatic closed-captioning built in, or upload their audio or video content to YouTube, which provides the option for automatic closed-captioning as well. An instructor could also pay for a professional to close-caption their content; however, such a solution requires a significant amount of time, money, and the captions might be inaccurate for lack of understanding of the content on the professional’s end. </p>

    <h3>2. Describe potential guidelines and solutions. </h3>

    <p>Web Accessibility Guideline 1.2.2 states that “captions are provided for all pre-recorded audio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such” (Web Content Accessibility Guidelines). All the existing solutions discussed require a manual process by which closed-captioning can be obtained by an instructor to make them accessible to viewers. An instructor would have to choose to create closed-captions through Kaltura, which has an accuracy of 70-80%, manually create closed-captions through the use of an SRT file to then be uploaded to ELC, or utilize a third-party platform. This affects not only students with hearing impairments, but all students because captions and text alternatives are not provided for the videos and audios unless the instructor does so manually. In an objective assessment, it has been found that subtitles and transcripts are more effective than videos without visual displays of texts, at delivering and providing complex information to students (Jae, 2019). While all these solutions would technically conform to guideline 1.2.2, at the initial upload of audio and video content, closed-captioning might not be available as a result of: the instructor waiting for a third-party to close-caption the video, the instructor has to wait the minimum thirty minute window for Kaltura to produce the subtitles, which may be inadequate, a viewer might not have access to the third-party platform being used by the instructor, or the instructor might not have access to a third-party platform, such as Zoom. </p>

    <h2>C. Proposed Solution</h2>

    <h3>1. Propose a solution. </h3>

    <p>The solution proposed is to implement an automatic closed-captioning and transcript function with an accuracy of 99%-100% within the ELC platform for instructor use upon uploading audio or video content. Additionally, this function will include a process by which sections of the audio or video content that fall below the 99% accuracy criteria, or that could not be transcribed at all due to error, will be automatically flagged for further review by the creator. Such a solution would reduce the amount of time and money spent by a creator to produce closed-captions and transcripts for audio and video content, as well as reduce the time it would take a creator to review the closed-captions and transcripts produced to determine any errors. With a 98%-100% accuracy, such a solution would allow for increased accessibility in regard to audio and video content for those with impaired hearing, or those who experience a language barrier. </p>

    <div class = "signifiers">
        <b>Signifiers</b>
        <ul>
            <li>All content viewers will see a ‘CC’ button in the content frame to add or remove closed-captioning when necessary</li>
            <li>All content viewers will see a ‘Transcript’ button below the content frame to allow direct access to a transcript of the content</li>
            <li>All content creators will see a ‘Create Closed-Captioning’ and ‘Create Transcript’ button upon content upload, which will automatically add such functions to the content</li>

        </ul>

        <b>Affordances</b>
        <ul>
            <li>Automatic, adequate closed-captioning for content creators</li>
            <li>Automatic transcripts are formulated for content creators upon content upload</li>
            <li>Closed-captioning available to all content viewers</li>
            <li>Transcripts available to all content viewers</li>
            <li>Content creators have the ability to edit any of the closed-captionings or transcripts if the software flags certain sections as inadequate</li>
        </ul>

        <b>Properties</b>
        <ul>
            <li>Content will be automatically closed-captioned and transcribed for content creators prior to the content being fully uploaded</li>
            <li>When a content viewer clicks on the uploaded content, a closed-captioning button can be selected and closed-captions will appear at the bottom of the content view</li>
            <li>A button labeled ‘Transcript’ will be present under the content view, and when clicked a window with the transcript of the closed-captions with time stamps will appear</li>
        </ul>
</div>

    <h3>2. How will you measure success? </h3>

    <p>Success will be measured by content creator uploaded videos being automatically closed-captioned, and content viewers having the option to turn closed-captioning on/off. If errors in the closed-captioning/transcripts exist, those sections of the content will be flagged for further content creator review. Additionally, content viewers will have the ability to view a transcript of the closed-captioning of the entirety of the content. Both closed-captioning and the transcript should accurately depict the audio in the content with 99-100% accuracy. </p>

    <h2>D. Summary Video</h2>
    <p>The Inclusive Dawgs uploaded a summary of our defined problem. The video can be accessed on YouTube, using the link below. A copy of the slide deck used is also linked below.</p>
    <div class = "signifiers">
        <ul>
            <li><a href = "https://youtu.be/ib1Jbm7VBHE">The Inclusive Dawgs Summary Video</a></li>
            <li><a href = "Milestone2Powerpoint.pdf">The Inclusive Dawgs Milestone 2 Slide Deck</a></li>
        </ul>


    <h2>Citations</h2>
        <ul>
            <li><a href = "https://help.elc.uga.edu/creating_content/kaltura_audio_and_video/"> “Captioning”, eLearning Commons, University of Georgia</a></li>
            <li><a href = "https://www.nytimes.com/2015/02/13/education/harvard-and-mit-sued-over-failing-to-caption-online-courses.html">Harvard and MIT are Sued Over Failing to Caption Online Courses</a></li>
            <li><a href = "https://files.eric.ed.gov/fulltext/EJ1216800.pdf">The effectiveness of closed caption videos in classrooms</a></li>
            <li><a href = "https://www.w3.org/TR/WCAG20/#media-equiv-av-only-alt">“Web Content Accessibility Guidelines (WCAG) 2.0”, w3, </a></li>
            <li><a href = "https://www.d2l.com/wp-content/uploads/2021/05/Brightspace-Core-%E2%80%93-Web-Content-Accessibility-Guidelines-WCAG-2.1-Checklist.pdf">“D2L Accessibility Conformance Report - WCAG 2.1 AA - March 31, 2021”, Desire2Learn</a></li>
            <li><a href = "https://www.rev.com/blog/ai-vs-human-transcription-accuracy">“AI vs. Human Transcription Accuracy for Speech-To-Text Services”, Rev, 08 August 202</a></li>
            <li><a href = "https://www.3playmedia.com/blog/long-take-manually-caption-videos/">Enamorado, Sofie, “How Long Does it Take to Manually Caption Videos?”, 3PlayMedia, 8 April 202</a></li>
            <li><a href = " https://files.eric.ed.gov/fulltext/EJ1216800.pdf">Jae, Haeran, “The effectiveness of closed caption videos in classrooms: objective versus subjective assessments”, Journal of Instructional Pedagogies, vol. 22, 2019</a></li>
        </ul>



    </div>
    <footer><br> &copy; 2021 The Inclusive Dawgs</footer>
</div>

</body>
</html>
